{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w6gPAocVRrN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "__Tf8BAy_Ons"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Using cached python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py): started\n",
      "  Building wheel for python-speech-features (setup.py): finished with status 'done'\n",
      "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5887 sha256=2bb9595fd3fb69264337423dd820da7021308ecfa16b0f7f7d4d79f0ca361669\n",
      "  Stored in directory: c:\\users\\yuusha\\appdata\\local\\pip\\cache\\wheels\\5b\\60\\87\\28af2605138deac93d162904df42b6fdda1dab9b8757c62aa3\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXBfWko58RRN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYWRHRvB8TFH"
   },
   "outputs": [],
   "source": [
    "# process features\n",
    "\n",
    "codes_path = \"./drive/MyDrive/606-project-data/Codes\"\n",
    "chunks_path = \"./drive/MyDrive/606-project-data/Chunks\"\n",
    "all_name = os.listdir(chunks_path)\n",
    "#val_name = ['Lily_ Pete the cat Day 5', 'Lily_ Stop and go Day 4 Part 2', 'Lily_ Cowboy Mouse Day 4B', 'Huang_ The princess and the pea']\n",
    "#test_name = [\"Liu_ Pete the Cat\", 'Lily_ Stop and go Day 4 Part 1', 'Lily_ Cowboy Mouse Day 4A', 'Huang_ Maisy Goes Camping Day 3']\n",
    "\n",
    "val_name = ['Lily_ Pete the cat Day 5']\n",
    "test_name = [\"Liu_ Pete the Cat\"]\n",
    "\n",
    "train_name = set(all_name) - set(val_name) - set(test_name)\n",
    "train_name = list(train_name)\n",
    "\n",
    "print(len(train_name)); print(train_name); print(len(val_name)); print(val_name); print(len(test_name)); print(test_name)\n",
    "print(val_name in train_name); print(test_name in train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA9PaD3How61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMYmNS5U_Wd3"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(train_name)):\n",
    "  print(train_name[i])\n",
    "  audios_path = chunks_path + '/' + train_name[i]\n",
    "\n",
    "  single_code_path = codes_path + '/' + train_name[i] + '.xlsx'\n",
    "  single_code_file = pd.ExcelFile(single_code_path)\n",
    "  single_code_file = single_code_file.parse('Sheet1', skiprows=5, index_col=None, usecols=range(1,10))\n",
    "  single_code_file.rename({'Lang of Instruction Teacher/Student': 'Lang of Instruction Teacher',\n",
    "                           'Unnamed: 9': 'Lang of Instruction Student'}, axis=1, inplace=True)\n",
    "  \n",
    "  predict_target = single_code_file['Lang of Instruction Teacher'] # change the prediction target here\n",
    "\n",
    "  for j in range(60):\n",
    "\n",
    "    single_20seconds_path = audios_path + '/' + train_name[i] + '[' + str(j) + '].wav'\n",
    "\n",
    "    (rate,sig) = wav.read(single_20seconds_path)\n",
    "\n",
    "    mfcc_feat = mfcc(sig, rate, nfft = 1103, winstep = 0.1) # change the feature type here\n",
    "    #mfcc_feat = mfcc(sig, rate)\n",
    "    #d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "    #fbank_feat = logfbank(sig,rate)\n",
    "    mfcc_feat = mfcc_feat.reshape(1, mfcc_feat.shape[0], mfcc_feat.shape[1])\n",
    "\n",
    "    label = predict_target[j] - 1\n",
    "\n",
    "    train_data.append({'feature': mfcc_feat, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7s1MgRv0ZhI"
   },
   "outputs": [],
   "source": [
    "val_data = []\n",
    "for i in range(len(val_name)):\n",
    "  print(val_name[i])\n",
    "  audios_path = chunks_path + '/' + val_name[i]\n",
    "\n",
    "  single_code_path = codes_path + '/' + val_name[i] + '.xlsx'\n",
    "  single_code_file = pd.ExcelFile(single_code_path)\n",
    "  single_code_file = single_code_file.parse('Sheet1', skiprows=5, index_col=None, usecols=range(1,10))\n",
    "  single_code_file.rename({'Lang of Instruction Teacher/Student': 'Lang of Instruction Teacher',\n",
    "                           'Unnamed: 9': 'Lang of Instruction Student'}, axis=1, inplace=True)\n",
    "  \n",
    "  predict_target = single_code_file['Lang of Instruction Teacher'] # change the prediction target here\n",
    "\n",
    "  for j in range(60):\n",
    "\n",
    "    single_20seconds_path = audios_path + '/' + val_name[i] + '[' + str(j) + '].wav'\n",
    "\n",
    "    (rate,sig) = wav.read(single_20seconds_path)\n",
    "\n",
    "    mfcc_feat = mfcc(sig, rate, nfft = 1103, winstep = 0.1) # change the feature type here\n",
    "    #mfcc_feat = mfcc(sig, rate)\n",
    "    #d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "    #fbank_feat = logfbank(sig,rate)\n",
    "    mfcc_feat = mfcc_feat.reshape(1, mfcc_feat.shape[0], mfcc_feat.shape[1])\n",
    "\n",
    "    label = predict_target[j] - 1\n",
    "\n",
    "    val_data.append({'feature': mfcc_feat, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBJBRuh80Zoi"
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(test_name)):\n",
    "  print(test_name[i])\n",
    "  audios_path = chunks_path + '/' + test_name[i]\n",
    "\n",
    "  single_code_path = codes_path + '/' + test_name[i] + '.xlsx'\n",
    "  single_code_file = pd.ExcelFile(single_code_path)\n",
    "  single_code_file = single_code_file.parse('Sheet1', skiprows=5, index_col=None, usecols=range(1,10))\n",
    "  single_code_file.rename({'Lang of Instruction Teacher/Student': 'Lang of Instruction Teacher',\n",
    "                           'Unnamed: 9': 'Lang of Instruction Student'}, axis=1, inplace=True)\n",
    "  \n",
    "  predict_target = single_code_file['Lang of Instruction Teacher'] # change the prediction target here\n",
    "\n",
    "  for j in range(60):\n",
    "\n",
    "    single_20seconds_path = audios_path + '/' + test_name[i] + '[' + str(j) + '].wav'\n",
    "\n",
    "    (rate,sig) = wav.read(single_20seconds_path)\n",
    "\n",
    "    mfcc_feat = mfcc(sig, rate, nfft = 1103, winstep = 0.1) # change the feature type here\n",
    "    #mfcc_feat = mfcc(sig, rate)\n",
    "    #d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "    #fbank_feat = logfbank(sig,rate)\n",
    "    mfcc_feat = mfcc_feat.reshape(1, mfcc_feat.shape[0], mfcc_feat.shape[1])\n",
    "\n",
    "    label = predict_target[j] - 1\n",
    "\n",
    "    test_data.append({'feature': mfcc_feat, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0_4BQG18OYE"
   },
   "outputs": [],
   "source": [
    "print(len(train_data)); print(len(test_data)); print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiuXh_9IgbOf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_train = []\n",
    "for i in range(len(train_data)):\n",
    "  if i == 0:\n",
    "    X_train = train_data[i]['feature']\n",
    "    Y_train.append(train_data[i]['label'])\n",
    "  else:\n",
    "    X_train = np.concatenate((X_train, train_data[i]['feature']), axis = 0)\n",
    "    Y_train.append(train_data[i]['label'])\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "\n",
    "Y_val = []\n",
    "for i in range(len(val_data)):\n",
    "  if i == 0:\n",
    "    X_val = val_data[i]['feature']\n",
    "    Y_val.append(val_data[i]['label'])\n",
    "  else:\n",
    "    X_val = np.concatenate((X_val, val_data[i]['feature']), axis = 0)\n",
    "    Y_val.append(val_data[i]['label'])\n",
    "    \n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "\n",
    "Y_test = []\n",
    "for i in range(len(test_data)):\n",
    "  if i == 0:\n",
    "    X_test = test_data[i]['feature']\n",
    "    Y_test.append(test_data[i]['label'])\n",
    "  else:\n",
    "    X_test = np.concatenate((X_test, test_data[i]['feature']), axis = 0)\n",
    "    Y_test.append(test_data[i]['label'])\n",
    "    \n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_train.shape); print(X_val.shape); print(X_test.shape); print(len(Y_train)); print(len(Y_val)); print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhSmjRwbhNch"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ko2jkWjgt4xY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wqD-MkrgJZa"
   },
   "outputs": [],
   "source": [
    "input_shape=(401,13)\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape = input_shape))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5,activation = 'softmax')) # 5 is the number of classes\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbD7tUTm6_N_"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\"\n",
    "    )\n",
    "]\n",
    "\n",
    "#callbacks = [\n",
    "#    keras.callbacks.ModelCheckpoint(\n",
    "#        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "#    ),\n",
    "#    keras.callbacks.ReduceLROnPlateau(\n",
    "#        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "#    ),\n",
    "#    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUmVtM4OgJbb"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v49wkVKZgJeG"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 20, batch_size = 60, callbacks=callbacks, \n",
    "                    validation_data=(X_val, Y_val), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8dLAqGVt444"
   },
   "outputs": [],
   "source": [
    "history_dict=history.history\n",
    "loss_values=history_dict['loss']\n",
    "acc_values=history_dict['accuracy']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "val_acc_values=history_dict['val_accuracy']\n",
    "epochs=range(1,21)\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
    "ax1.plot(epochs,loss_values,'co',label='Training Loss')\n",
    "ax1.plot(epochs,val_loss_values,'m', label='Validation Loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax2.plot(epochs,acc_values,'co', label='Training accuracy')\n",
    "ax2.plot(epochs,val_acc_values,'m',label='Validation accuracy')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hkf_FQf3GAX"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")\n",
    "\n",
    "TrainLoss, Trainacc = model.evaluate(X_train, Y_train)\n",
    "ValLoss, Valacc = model.evaluate(X_val, Y_val)\n",
    "TestLoss, Testacc = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"Accuracy on training set\", Trainacc)\n",
    "\n",
    "print(\"Accuracy on val set\", Valacc)\n",
    "\n",
    "print(\"Accuracy on test set\", Testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muEYbrKT35Ro"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(np.argmax(Y_pred,axis=1))\n",
    "print(Y_test)\n",
    "print('Confusion_matrix: ',tf.math.confusion_matrix(Y_test, np.argmax(Y_pred,axis=1)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "606SW-project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
